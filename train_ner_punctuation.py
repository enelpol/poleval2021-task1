import pandas as pd
import numpy as np
import sklearn
import argparse
import os
from simpletransformers.ner import NERArgs, NERModel
import torch
import time
from utils import load_data_as_dataframe
import wandb


labels = ['B', ':', ';', ',', '.', '-', '...', '?', '!']


def f1_per_label(y_true, y_pred):
    values = merge_data(sklearn.metrics.f1_score, y_true, y_pred, labels=labels[1:], average=None, zero_division=0)
    return {str(i): v for i, v in enumerate(values)}


def pr_per_label(y_true, y_pred):
    values = merge_data(sklearn.metrics.precision_score, y_true, y_pred, labels=labels[1:], average=None, zero_division=0)
    return {str(i): v for i, v in enumerate(values)}
    # return values[label]


def rc_per_label(y_true, y_pred):
    values = merge_data(sklearn.metrics.recall_score, y_true, y_pred, labels=labels[1:], average=None, zero_division=0)
    return {str(i): v for i, v in enumerate(values)}
    # return values[label]


def merge_data(func, y_true, y_pred, **kwargs):
    y_true_res = []
    y_pred_res = []

    for t in y_true:
        y_true_res.extend(t)

    for p in y_pred:
        y_pred_res.extend(p)

    return func(y_true_res, y_pred_res, **kwargs)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--train_data_dir', type=str, default='ner_train', help='path to train data directory')
    parser.add_argument('--eval_data_dir', type=str, default='ner_dev', help='path to train data directory')
    parser.add_argument('--test_data_dir', type=str, default='ner_test', help='path to test data directory')
    parser.add_argument('--wandb_project', type=str, default='poleval2021_task1', help='wandb project id')
    parser.add_argument('--epochs', type=int, default=5)
    parser.add_argument('--learning_rate', type=float, default=5e-5, help='learnign rate')
    parser.add_argument('--batch_size', type=int, default=32, help='batch size')
    parser.add_argument('--acc', type=int, default=1, help='gradient accumulation steps')
    parser.add_argument('--model_name', type=str, default='allegro/herbert-base-cased', help='path to model')
    parser.add_argument('--model_type', type=str, default='herbert', help='model type')
    parser.add_argument('--warmup_steps', type=int, default=1, help='warmup steps')
    parser.add_argument('--eval_steps', type=int, default=100, help='eval steps')
    parser.add_argument('--eval_during_training', action='store_true')
    parser.add_argument('--max_seq_len', type=int,  default=256)
    parser.add_argument('--use_dice', action='store_true')
    parser.add_argument('--use_focal', action='store_true')
    parser.add_argument('--focal_alpha', default=0.25, type=float)
    parser.add_argument('--seed', type=int, default=81945)
    parser.add_argument('--early_stopping_metric', type=str, default='f1_weighted')
    parser.add_argument('--weights', nargs="+", type=float, default=None)
    args = parser.parse_args()

    print(args.weights)

    #train_data = load_data_as_dataframe(args.train_data_dir)
    #eval_data = load_data_as_dataframe(args.eval_data_dir)

    train_data = pd.read_csv(args.train_data_dir, sep='\t', header=0)
    eval_data = pd.read_csv(args.eval_data_dir, sep='\t', header=0)

    sentences_to_delete = train_data[~train_data.labels.isin(labels)].sentence_id #co≈õ to robi?
    train_data = train_data.loc[~train_data.sentence_id.isin(sentences_to_delete)]

    sentences_to_delete = eval_data[~eval_data.labels.isin(labels)].sentence_id
    eval_data = eval_data.loc[~eval_data.sentence_id.isin(sentences_to_delete)]

    ner_args = NERArgs()
    ner_args.early_stopping_metric = args.early_stopping_metric
    ner_args.early_stopping_metric_minimize = False
    ner_args.model_type = args.model_type
    ner_args.model_name = args.model_name
    ner_args.wandb_project = args.wandb_project
    ner_args.wandb_kwargs = {"settings": wandb.Settings(start_method="thread")}
    ner_args.train_batch_size = args.batch_size
    ner_args.eval_batch_size = args.batch_size
    ner_args.gradient_accumulation_steps = args.acc
    ner_args.learning_rate = args.learning_rate
    ner_args.num_train_epochs = args.epochs
    ner_args.evaluate_during_training = args.eval_during_training
    ner_args.evaluate_during_training_steps = 20 # args.eval_steps
    ner_args.max_seq_length = args.max_seq_len
    ner_args.manual_seed = args.seed
    ner_args.warmup_steps = args.warmup_steps
    ner_args.save_eval_checkpoints = False
    ner_args.use_multiprocessing = False
    ner_args.use_multiprocessing_for_evaluation = False

    if args.use_dice:
        ner_args.loss_type = 'dice'
        ner_args.loss_args = {
            'smooth': 0.001,
            'square_denominator': True,
            'with_logits': True,
            'ohem_ratio': 0.0,
            'alpha': 0,
            'reduction': "mean",
            'index_label_position': True
        }
    if args.use_focal:
        ner_args.loss_type = 'focal'
        ner_args.loss_args = {
            'alpha': args.focal_alpha,
            'gamma': 2,
            'reduction': 'mean',
            'eps': 1e-6,
            'ignore_index': -100,
        }

    metrics = {
        'f1_micro': lambda y_true, y_pred: merge_data(sklearn.metrics.f1_score, y_true, y_pred, average='micro',
                                                      zero_division=0, labels=labels[1:]),
        'f1_macro': lambda y_true, y_pred: merge_data(sklearn.metrics.f1_score, y_true, y_pred, average='macro',
                                                      zero_division=0, labels=labels[1:]),
        'f1_weighted': lambda y_true, y_pred: merge_data(sklearn.metrics.f1_score, y_true, y_pred, average='weighted',
                                                         zero_division=0, labels=labels[1:]),
        'pr_micro': lambda y_true, y_pred: merge_data(sklearn.metrics.precision_score, y_true, y_pred, average='micro',
                                                      zero_division=0, labels=labels[1:]),
        'pr_macro': lambda y_true, y_pred: merge_data(sklearn.metrics.precision_score, y_true, y_pred, average='macro',
                                                      zero_division=0, labels=labels[1:]),
        'pr_weighted': lambda y_true, y_pred: merge_data(sklearn.metrics.precision_score, y_true, y_pred, average='weighted',
                                                      zero_division=0, labels=labels[1:]),
        'rc_micro': lambda y_true, y_pred: merge_data(sklearn.metrics.recall_score, y_true, y_pred, average='micro',
                                                                        zero_division=0, labels=labels[1:]),
        'rc_macro': lambda y_true, y_pred: merge_data(sklearn.metrics.recall_score, y_true, y_pred, average='macro',
                                                                        zero_division=0, labels=labels[1:]),
        'rc_weighted': lambda y_true, y_pred: merge_data(sklearn.metrics.recall_score, y_true, y_pred, average='weighted',
                                                      zero_division=0, labels=labels[1:]),
        #'classification_report': lambda y_true, y_pred: sklearn.metrics.classification_report(y_true, y_pred,
        #                                                                                      output_dict=True),
        'confusion_matrix': lambda y_true, y_pred: merge_data(sklearn.metrics.confusion_matrix, y_true, y_pred,
                                                              labels=labels[1:]),

        'f1_class': lambda y_true, y_pred: f1_per_label(y_true, y_pred),
        'pr_class': lambda y_true, y_pred: pr_per_label(y_true, y_pred),
        'rc_class': lambda y_true, y_pred: rc_per_label(y_true, y_pred),
    }

    #labels = list(train_data.labels.unique())
    train_data.words = train_data.words.astype(str)
    eval_data.words = eval_data.words.astype(str)
    print('labels', labels)
    start = time.time()
    output_dir = f'model_dir_{args.model_name}_{start}'

    ner_args.output_dir = output_dir
    ner_args.best_model_dir = os.path.join(output_dir, 'best_model')
    model = NERModel(args.model_type, args.model_name,
                     labels=labels, args=ner_args, weight=args.weights,
                     use_cuda=True if torch.cuda.is_available() else False)

    model.train_model(train_data, output_dir=output_dir, eval_data=eval_data, **metrics)

    #with open('test-A/in.tsv') as f:
    #    to_predict = [line.split('\t')[1] for line in f]

    #print(model.predict(to_predict, split_on_space=True))

